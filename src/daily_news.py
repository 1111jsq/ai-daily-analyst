"""
æ¯æ—¥ AI æ–°é—»æŠ“å–ä¸åˆ†æ
"""
import os
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional
import hashlib

from tavily import TavilyClient

from .config import (
    TAVILY_API_KEY,
    SEARCH_DEPTH,
    MAX_RESULTS,
    DAILY_TOPICS,
    DATA_DIR,
    OUTPUT_DIR,
    LOG_LEVEL,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class DailyNewsCollector:
    """æ¯æ—¥æ–°é—»æ”¶é›†å™¨"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or TAVILY_API_KEY
        if not self.api_key:
            raise ValueError("Tavily API key is required")
        self.client = TavilyClient(api_key=self.api_key)

    def search_topic(self, topic: str, days: int = 1) -> List[Dict]:
        """æœç´¢å•ä¸ªä¸»é¢˜çš„æ–°é—»"""
        query = f"{topic} AI news"
        try:
            results = self.client.search(
                query=query,
                search_depth=SEARCH_DEPTH,
                max_results=MAX_RESULTS,
                include_answer=True,
                include_raw_content=False,
            )
            logger.info(f"æœç´¢ '{topic}' è·å¾— {len(results.get('results', []))} æ¡ç»“æœ")
            return results
        except Exception as e:
            logger.error(f"æœç´¢ '{topic}' å¤±è´¥: {e}")
            return {}

    def collect_daily_news(self, date: Optional[datetime] = None) -> Dict:
        """æ”¶é›†å½“æ—¥æ‰€æœ‰ä¸»é¢˜çš„æ–°é—»"""
        date = date or datetime.now()
        date_str = date.strftime("%Y-%m-%d")
        
        all_results = {
            "date": date_str,
            "topics": {},
            "ai_answer": "",
            "articles": [],
        }

        # æœç´¢æ¯ä¸ªä¸»é¢˜
        for topic in DAILY_TOPICS:
            logger.info(f"æ­£åœ¨æœç´¢: {topic}")
            result = self.search_topic(topic)
            if result:
                all_results["topics"][topic] = result
                # æ”¶é›†æ–‡ç« 
                for item in result.get("results", []):
                    article = {
                        "title": item.get("title", ""),
                        "url": item.get("url", ""),
                        "content": item.get("content", "")[:200],
                        "score": item.get("score", 0),
                        "topic": topic,
                    }
                    all_results["articles"].append(article)

        # AI æ€»ç»“
        if all_results["topics"]:
            first_topic = list(all_results["topics"].values())[0]
            all_results["ai_answer"] = first_topic.get("answer", "")

        return all_results

    def save_news(self, news_data: Dict) -> Path:
        """ä¿å­˜æ–°é—»æ•°æ®åˆ°æ–‡ä»¶"""
        date_str = news_data["date"]
        filename = f"news_{date_str}.json"
        filepath = DATA_DIR / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(news_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ–°é—»æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath


class DailyAnalyst:
    """æ¯æ—¥åˆ†æå¸ˆ"""

    def __init__(self, news_collector: DailyNewsCollector):
        self.collector = news_collector

    def generate_analysis(self, news_data: Dict) -> str:
        """ç”Ÿæˆæ¯æ—¥åˆ†ææ–‡ç« """
        date_str = news_data["date"]
        articles = news_data.get("articles", [])
        ai_answer = news_data.get("ai_answer", "")

        # æŒ‰åˆ†æ•°æ’åºï¼Œå–å‰10
        top_articles = sorted(articles, key=lambda x: x.get("score", 0), reverse=True)[:10]

        # ç”Ÿæˆæ–‡ç« 
        content = f"""# æ¯æ—¥ AI åŠ¨æ€åˆ†æ - {date_str}

## ä»Šæ—¥ AI é¢†åŸŸè¦é—»

"""

        if ai_answer:
            content += f"**AI æ€»ç»“ï¼š**{ai_answer}\n\n"

        content += "## é‡ç‚¹æ–°é—»\n\n"

        for i, article in enumerate(top_articles, 1):
            content += f"### {i}. {article['title']}\n"
            content += f"**æ¥æºï¼š** {article.get('url', 'Unknown')}\n"
            content += f"**ç›¸å…³é¢†åŸŸï¼š** {article.get('topic', 'AI')}\n"
            if article.get("content"):
                content += f"\n{article['content']}\n"
            content += "\n---\n\n"

        # æ·»åŠ åˆ†æç»“è¯­
        content += f"""
## åˆ†ææ€»ç»“

ä»Šæ—¥ AI é¢†åŸŸå…±æ”¶é›†åˆ° {len(articles)} æ¡ç›¸å…³æ–°é—»ï¼Œä»¥ä¸Šä¸ºæœ€å…·å½±å“åŠ›çš„ {len(top_articles)} æ¡ã€‚

**å…³æ³¨ç„¦ç‚¹ï¼š** æœ¬æ—¥æ–°é—»ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹æ›´æ–°ã€äº§å“å‘å¸ƒå’Œåº”ç”¨è½åœ°ç­‰æ–¹é¢ã€‚

---
*æœ¬æ–‡ç”± AI è‡ªåŠ¨ç”Ÿæˆ | å‘å¸ƒæ—¥æœŸï¼š{date_str}*
"""

        return content

    def save_article(self, content: str, date_str: str) -> Path:
        """ä¿å­˜åˆ†ææ–‡ç« """
        filename = f"article_{date_str}.md"
        filepath = OUTPUT_DIR / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        logger.info(f"åˆ†ææ–‡ç« å·²ä¿å­˜åˆ°: {filepath}")
        return filepath

    def run(self, date: Optional[datetime] = None) -> Dict:
        """è¿è¡Œæ¯æ—¥åˆ†ææµç¨‹"""
        date = date or datetime.now()
        date_str = date.strftime("%Y-%m-%d")
        
        logger.info(f"å¼€å§‹ç”Ÿæˆ {date_str} çš„æ¯æ—¥åˆ†æ...")
        
        # 1. æ”¶é›†æ–°é—»
        news_data = self.collector.collect_daily_news(date)
        
        # 2. ä¿å­˜åŸå§‹æ•°æ®
        self.collector.save_news(news_data)
        
        # 3. ç”Ÿæˆåˆ†æ
        article_content = self.generate_analysis(news_data)
        
        # 4. ä¿å­˜æ–‡ç« 
        article_path = self.save_article(article_content, date_str)
        
        return {
            "date": date_str,
            "article_path": str(article_path),
            "articles_count": len(news_data.get("articles", [])),
        }


def main():
    """ä¸»å‡½æ•°"""
    collector = DailyNewsCollector()
    analyst = DailyAnalyst(collector)
    result = analyst.run()
    print(f"âœ… æ¯æ—¥åˆ†æå®Œæˆï¼")
    print(f"ğŸ“… æ—¥æœŸ: {result['date']}")
    print(f"ğŸ“„ æ–‡ç« : {result['article_path']}")
    print(f"ğŸ“Š æ”¶é›†æ–‡ç« æ•°: {result['articles_count']}")


if __name__ == "__main__":
    main()
