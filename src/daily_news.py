"""
æ¯æ—¥ AI æ–°é—»æŠ“å–ä¸åˆ†æ - å¾®ä¿¡å…¬ä¼—å·ç‰ˆæœ¬
"""
import os
import json
import logging
import re
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional
from collections import Counter

from .config import (
    TAVILY_API_KEY,
    SEARCH_DEPTH,
    MAX_RESULTS,
    DAILY_TOPICS,
    DATA_DIR,
    OUTPUT_DIR,
    LOG_LEVEL,
    TECH_CATEGORIES,
    SOURCES_CONFIG,
)

from .web_fetcher import NewsCollector

logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class DailyNewsCollector:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or TAVILY_API_KEY
        self.client = None
        if self.api_key:
            try:
                from tavily import TavilyClient
                self.client = TavilyClient(api_key=self.api_key)
            except Exception as e:
                logger.warning(f"Tavily client init failed: {e}")
        
        self.news_collector = NewsCollector(SOURCES_CONFIG)

    def search_topic(self, topic: str, days: int = 1) -> List[Dict]:
        if not self.client:
            return {"answer": "", "results": []}
        
        query = f"{topic} AI news"
        try:
            results = self.client.search(
                query=query,
                search_depth=SEARCH_DEPTH,
                max_results=MAX_RESULTS,
                include_answer=True,
                include_raw_content=False,
            )
            logger.info(f"æœç´¢ '{topic}' è·å¾— {len(results.get('results', []))} æ¡ç»“æœ")
            return results
        except Exception as e:
            logger.error(f"æœç´¢ '{topic}' å¤±è´¥: {e}")
            return {"answer": "", "results": []}

    def collect_daily_news(self, date: Optional[datetime] = None) -> Dict:
        date = date or datetime.now()
        date_str = date.strftime("%Y-%m-%d")
        
        all_results = {
            "date": date_str,
            "topics": {},
            "ai_answer": "",
            "articles": [],
        }

        web_articles = self.news_collector.collect(max_items=15)
        if web_articles:
            logger.info(f"ä»Webæºè·å– {len(web_articles)} æ¡æ–°é—»")
            all_results["articles"].extend(web_articles)

        if self.client:
            for topic in DAILY_TOPICS[:5]:
                logger.info(f"æ­£åœ¨æœç´¢: {topic}")
                result = self.search_topic(topic)
                if result:
                    all_results["topics"][topic] = result
                    for item in result.get("results", []):
                        article = {
                            "title": item.get("title", ""),
                            "url": item.get("url", ""),
                            "content": item.get("content", "")[:200],
                            "score": item.get("score", 0),
                            "topic": topic,
                            "source": item.get("url", "").split("/")[2] if "/" in item.get("url", "") else "Unknown",
                        }
                        all_results["articles"].append(article)

        if all_results["topics"]:
            first_topic = list(all_results["topics"].values())[0]
            all_results["ai_answer"] = first_topic.get("answer", "")

        if not all_results["ai_answer"] and web_articles:
            all_results["ai_answer"] = f"ä»Šæ—¥AIé¢†åŸŸå…±æ”¶é›†{len(web_articles)}æ¡æœ€æ–°èµ„è®¯ï¼Œæ¶µç›–æ™ºèƒ½ä½“ã€å¤§æ¨¡å‹ç­‰æŠ€æœ¯é¢†åŸŸã€‚"

        return all_results

    def save_news(self, news_data: Dict) -> Path:
        date_str = news_data["date"]
        filename = f"news_{date_str}.json"
        filepath = DATA_DIR / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(news_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ–°é—»æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath


def categorize_article(title: str, content: str = "") -> str:
    text = (title + " " + content).lower()
    for category, keywords in TECH_CATEGORIES.items():
        for kw in keywords:
            if kw.lower() in text:
                return category
    return "å…¶ä»–"


class DailyAnalyst:
    def __init__(self, news_collector: DailyNewsCollector):
        self.collector = news_collector

    def categorize_articles(self, articles: List[Dict]) -> Dict[str, List[Dict]]:
        categorized = {cat: [] for cat in TECH_CATEGORIES.keys()}
        categorized["å…¶ä»–"] = []
        
        for article in articles:
            category = categorize_article(article.get("title", ""), article.get("content", ""))
            categorized[category].append(article)
        
        return {k: v for k, v in categorized.items() if v}

    def generate_wechat_article(self, news_data: Dict) -> str:
        date_str = news_data["date"]
        articles = news_data.get("articles", [])
        ai_answer = news_data.get("ai_answer", "")

        categorized = self.categorize_articles(articles)
        top_articles = sorted(articles, key=lambda x: x.get("score", 0), reverse=True)[:8]
        
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        date_display = date_obj.strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        content = f"""ã€{date_display} AI Dailyã€‘

ğŸ“¢ ä»Šæ—¥è¦é—»é€Ÿè§ˆ

{ai_answer if ai_answer else "ä»Šæ—¥AIé¢†åŸŸä¼ æ¥å¤šé¡¹æŠ€æœ¯è¿›å±•ï¼Œå„å¤§å‚å•†æŒç»­å‘åŠ›ï¼Œå¤§æ¨¡å‹ã€å…·èº«æ™ºèƒ½ã€æ™ºèƒ½ä½“ç­‰é¢†åŸŸå‡æœ‰é‡å¤§æ›´æ–°ã€‚"}

ğŸ“° é‡ç‚¹æ–°é—»

"""

        for i, article in enumerate(top_articles, 1):
            source = article.get("source", "")
            content += f"{i}. {article['title']}\n"
            if source:
                content += f"   ğŸ”— {source}\n"
            content += "\n"

        content += "ğŸ“Š çƒ­é—¨æ¿å—\n\n"
        
        for cat, arts in sorted(categorized.items(), key=lambda x: len(x[1]), reverse=True)[:4]:
            if arts:
                content += f"â–¸ {cat}ï¼š{len(arts)}æ¡\n"
        
        content += f"""
---

ğŸ’¬ ä»Šæ—¥äº’åŠ¨

ä½ æ›´å…³æ³¨AIå“ªä¸ªé¢†åŸŸçš„å‘å±•ï¼Ÿ
æ¬¢è¿åœ¨è¯„è®ºåŒºç•™è¨€è®¨è®ºï¼

å¾€æœŸå›é¡¾ï¼š
â€¢ 2025å¹´2æœˆ14æ—¥ AI Daily
â€¢ 2025å¹´2æœˆ13æ—¥ AI Daily

ğŸ‘‰ ç‚¹å‡»å…³æ³¨ï¼Œäº†è§£æ›´å¤šAIèµ„è®¯"""

        return content

    def generate_full_article(self, news_data: Dict) -> str:
        date_str = news_data["date"]
        articles = news_data.get("articles", [])
        ai_answer = news_data.get("ai_answer", "")

        categorized = self.categorize_articles(articles)
        top_articles = sorted(articles, key=lambda x: x.get("score", 0), reverse=True)[:10]

        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        date_display = date_obj.strftime("%Yå¹´%mæœˆ%dæ—¥")

        content = f"""# {date_display} AI Daily

> æ¯å¤©3åˆ†é’Ÿï¼Œäº†è§£AIé¢†åŸŸæœ€æ–°åŠ¨æ€

---

**ä»Šæ—¥è¦é—»**ï¼š{ai_answer if ai_answer else "ä»Šæ—¥AIé¢†åŸŸä¼ æ¥å¤šé¡¹æŠ€æœ¯è¿›å±•ï¼Œå„å¤§å‚å•†æŒç»­å‘åŠ›ã€‚"}

---

## ä¸€ã€é‡ç‚¹æ–°é—»

"""

        for i, article in enumerate(top_articles, 1):
            cat = categorize_article(article.get("title", ""), article.get("content", ""))
            source = article.get("source", "")
            content += f"### {i}. {article['title']}\n\n"
            content += f"**æ¥æº**ï¼š{source}  |  **ç±»åˆ«**ï¼š{cat}\n\n"
            if article.get("content"):
                content += f"_{article['content']}_\n\n"
            content += "---\n\n"

        content += "## äºŒã€æŠ€æœ¯åˆ†ç±»\n\n"
        
        for cat, arts in sorted(categorized.items(), key=lambda x: len(x[1]), reverse=True):
            if arts:
                content += f"**{cat}** ({len(arts)}ç¯‡)\n\n"
                for art in arts[:3]:
                    content += f"- {art['title'][:50]}\n"
                content += "\n"

        content += f"""---

## ä¸‰ã€æ•°æ®ç»Ÿè®¡

- ä»Šæ—¥èµ„è®¯ï¼š{len(articles)}æ¡
- æŠ€æœ¯é¢†åŸŸï¼š{len(categorized)}ä¸ª
- çƒ­é—¨è¯é¢˜ï¼š{', '.join(list(categorized.keys())[:3])}

---

*æœ¬æ–‡å†…å®¹ç”±AIè‡ªåŠ¨æ•´ç†ï¼Œä»…ä¾›å‚è€ƒ*
"""

        return content

    def save_article(self, content: str, date_str: str, prefix: str = "article") -> Path:
        filename = f"{prefix}_{date_str}.md"
        filepath = OUTPUT_DIR / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        logger.info(f"æ–‡ç« å·²ä¿å­˜åˆ°: {filepath}")
        return filepath

    def run(self, date: Optional[datetime] = None) -> Dict:
        date = date or datetime.now()
        date_str = date.strftime("%Y-%m-%d")
        
        logger.info(f"å¼€å§‹ç”Ÿæˆ {date_str} çš„æ¯æ—¥åˆ†æ...")
        
        news_data = self.collector.collect_daily_news(date)
        self.collector.save_news(news_data)
        
        wechat_content = self.generate_wechat_article(news_data)
        wechat_path = self.save_article(wechat_content, date_str, "wechat_article")
        
        full_content = self.generate_full_article(news_data)
        full_path = self.save_article(full_content, date_str, "article")
        
        return {
            "date": date_str,
            "wechat_path": str(wechat_path),
            "article_path": str(full_path),
            "articles_count": len(news_data.get("articles", [])),
        }


def main():
    parser = argparse.ArgumentParser(description="AI Daily News Generator")
    parser.add_argument("--date", type=str, default=None, help="æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)")
    args = parser.parse_args()
    
    if args.date:
        target_date = datetime.strptime(args.date, "%Y-%m-%d")
    else:
        target_date = datetime.now()
    
    collector = DailyNewsCollector()
    analyst = DailyAnalyst(collector)
    result = analyst.run(target_date)
    
    print("Daily news generated!")
    print(f"Date: {result['date']}")
    print(f"WeChat article: {result['wechat_path']}")
    print(f"Full article: {result['article_path']}")
    print(f"Articles collected: {result['articles_count']}")


if __name__ == "__main__":
    main()
